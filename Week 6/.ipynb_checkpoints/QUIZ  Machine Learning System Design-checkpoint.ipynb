{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You are working on a spam classification system using regularized logistic regression. \"Spam\" is a positive class (y = 1) and \"not spam\" is the negative class (y = 0). You have trained your classifier and there are m = 1000 examples in the cross-validation set. The chart of predicted class vs. actual class is:\n",
    "![](https://github.com/amarsic1990/Coursera-Machine-Learning-by-Stanford-University/blob/master/Week%206/pictures/2.PNG?raw=true)\n",
    "    - 0.85\n",
    "2. Suppose a massive dataset is available for training a learning algorithm. Training on a lot of data is likely to give good performance when two of the following conditions hold true. Which are the two?\n",
    "    - A human expert on the application domain can confidently predict y when given only the features x (or more generally, if we have some way to be confident that x contains sufficient information to predict y accurately).\n",
    "    - Our learning algorithm is able to represent fairly complex functions (for example, if we train a neural network or other model with a large number of parameters).\n",
    "3. Suppose you have trained a logistic regression classifier which is outputing hθ(x). Currently, you predict 1 if hθ(x)≥threshold, and predict 0 if hθ(x)<threshold, where currently the threshold is set to 0.5. Suppose you decrease the threshold to 0.3. Which of the following are true? Check all that apply.\n",
    "    - The classifier is likely to now have higher recall.\n",
    "4. Suppose you are working on a spam classifier, where spam emails are positive examples (y=1) and non-spam emails are negative examples (y=0). You have a training set of emails in which 99% of the emails are non-spam and the other 1% is spam. Which of the following statements are true? Check all that apply.\n",
    "    - If you always predict non-spam (output y=0), your classifier will have 99% accuracy on the training set, and it will likely perform similarly on the cross validation set.\n",
    "    - A good classifier should have both a high precision and high recall on the cross validation set.\n",
    "    - If you always predict non-spam (output y=0), your classifier will have an accuracy of 99%.\n",
    "5. Which of the following statements are true? Check all that apply.\n",
    "    - Using a very large training set makes it unlikely for model to overfit the training data.\n",
    "    - The \"error analysis\" process of manually examining the examples which your algorithm got wrong can help suggest what are good steps to take (e.g., developing new features) to improve your algorithm's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
