{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You train a learning algorithm, and find that it has unacceptably high error on the test set. You plot the learning curve, and obtain the figure below. Is the algorithm suffering from high bias, high variance, or neither?\n",
    "![](https://github.com/amarsic1990/Coursera-Machine-Learning-by-Stanford-University/blob/master/Week%206/pictures/1.PNG?raw=true)\n",
    "    - High bias\n",
    "2. Suppose you have implemented regularized logistic regression to classify what object is in an image (i.e., to do object recognition). However, when you test your hypothesis on a new set of images, you find that it makes unacceptably large errors with its predictions on the new images. However, your hypothesis performs well (has low error) on the training set. Which of the following are promising steps to take? Check all that apply.\n",
    "    - Try using a smaller set of features.\n",
    "    - Try increasing the regularization parameter λ.\n",
    "3. Suppose you have implemented regularized logistic regression to predict what items customers will purchase on a web shopping site. However, when you test your hypothesis on a new set of customers, you find that it makes unacceptably large errors in its predictions. Furthermore, the hypothesis performs poorly on the training set. Which of the following might be promising steps to take? Check all that apply.\n",
    "    - Try adding polynomial features.\n",
    "    - Try to obtain and use additional features.\n",
    "4. Which of the following statements are true? Check all that apply.\n",
    "    - Suppose you are using linear regression to predict housing prices, and your dataset comes sorted in order of increasing sizes of houses. It is then important to randomly shuffle the dataset before splitting it into training, validation and test sets, so that we don’t have all the smallest houses going into the training set, and all the largest houses going into the test set.\n",
    "    - A typical split of a dataset into training, validation and test sets might be 60% training set, 20% validation set, and 20% test set.\n",
    "5. Which of the following statements are true? Check all that apply.\n",
    "    - If a learning algorithm is suffering from high variance, adding more training examples is likely to improve the test error.\n",
    "    - A model with more parameters is more prone to overfitting and typically has higher variance.\n",
    "    - When debugging learning algorithms, it is useful to plot a learning curve to understand if there is a high bias or high variance problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
